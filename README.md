# Projeto de PrediÃ§Ã£o de Churn - TelecomunicaÃ§Ãµes

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.0+-orange.svg)](https://tensorflow.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.0+-red.svg)](https://pytorch.org/)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.0+-green.svg)](https://scikit-learn.org/)

## ğŸ¯ Objetivo

Desenvolver modelos preditivos para detectar **churn de clientes** em uma empresa de telecomunicaÃ§Ãµes, utilizando diferentes algoritmos de machine learning e deep learning. Este projeto implementa uma soluÃ§Ã£o completa desde o prÃ©-processamento atÃ© a avaliaÃ§Ã£o, com **documentaÃ§Ã£o integralmente em portuguÃªs brasileiro** e comparaÃ§Ã£o sistemÃ¡tica entre mÃºltiplas abordagens.

## ğŸ‘¥ Equipe

| Nome | Login | Responsabilidade |
|------|-------|------------------|
| **Brenda Guerra** | `bvga` | AnÃ¡lise exploratÃ³ria e visualizaÃ§Ã£o dos modelos |
| **Yasmin Maria Wanderley Soares** | `ymws` | IntegraÃ§Ã£o, documentaÃ§Ã£o e apresentaÃ§Ã£o |
| **Gabriel Ferreira da Silva** | `gfs4` | Modelagem com MLP e STAB Transformer |
| **Lucas Santiago Monterazo** | `lsm6` | PrÃ©-processamento e engenharia de features |
| **Matheus Correia** | `mcr` | Modelagem com Random Forest e Gradient Boosting |

## ğŸš€ Como Executar

### 1. **PrÃ©-requisitos**
- Python 3.8 ou superior
- Jupyter Notebook ou Google Colab (recomendado)
- CUDA (opcional, para aceleraÃ§Ã£o GPU)

### 2. **InstalaÃ§Ã£o das DependÃªncias**
```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd ProjetoChurn

# Instale as dependÃªncias principais
pip install tensorflow torch scikit-learn pandas numpy xgboost
pip install matplotlib seaborn tabpfn joblib scipy kagglehub
```

### 3. **ExecuÃ§Ã£o Recomendada**

#### ğŸ““ **Notebook Principal (RECOMENDADO)**
```bash
# Abra o notebook principal com documentaÃ§Ã£o completa em PT-BR
jupyter notebook Churn.ipynb
```

**ğŸ’¡ Por que usar este notebook?**
- âœ… **DocumentaÃ§Ã£o 100% em portuguÃªs brasileiro**
- âœ… **Pipeline completo de ML desde limpeza atÃ© avaliaÃ§Ã£o**
- âœ… **5 experimentaÃ§Ãµes detalhadas com MLP**
- âœ… **ImplementaÃ§Ã£o de TabPFN e STAB Transformer**
- âœ… **FunÃ§Ãµes reutilizÃ¡veis bem documentadas**
- âœ… **VisualizaÃ§Ãµes ricas e anÃ¡lises detalhadas**

#### ğŸ“Š **Notebooks Alternativos**
```bash
# VersÃ£o intermediÃ¡ria
jupyter notebook Churn_RebasedPT.ipynb

# Notebook original com deep learning
jupyter notebook projetao/Churn\(2\)\(1\).ipynb
```

## ğŸ§  Modelos Implementados

### ğŸ”® **Redes Neurais e Deep Learning**

#### **MLP (Multi-Layer Perceptron) - 5 ExperimentaÃ§Ãµes**
1. **ExperimentaÃ§Ã£o 1**: 1 camada oculta (10 neurÃ´nios) + Adam + CrossEntropy
2. **ExperimentaÃ§Ã£o 2**: 3 camadas ocultas + Dropout (0.3) + RMSprop  
3. **ExperimentaÃ§Ã£o 3**: 2 camadas ocultas (20 neurÃ´nios) + RMSprop
4. **ExperimentaÃ§Ã£o 4**: AtivaÃ§Ã£o tanh + RMSprop + arquitetura customizada
5. **ExperimentaÃ§Ã£o 5**: RegularizaÃ§Ã£o L2 + Adadelta + early stopping

#### **Modelos Especializados**
- **ğŸ¤– STAB Transformer**: Transformer adaptado para dados tabulares
  - ConfiguraÃ§Ãµes: 2, 4, 8 e 16 attention heads
  - 1 e 2 camadas com dropout configurÃ¡vel
- **âš¡ TabPFN**: Prior-Data Fitted Networks para classificaÃ§Ã£o tabular
  - Modelo prÃ©-treinado especializado em dados tabulares

### ğŸŒ³ **Modelos Tree-based ClÃ¡ssicos**
- **ğŸŒ² Random Forest**: Ensemble de Ã¡rvores de decisÃ£o
- **ğŸ“ˆ Gradient Boosting**: ImplementaÃ§Ã£o clÃ¡ssica do sklearn  
- **ğŸš€ XGBoost**: Gradient boosting extremo otimizado

##  Tecnologias Utilizadas

### ğŸ“š **Core Machine Learning**
```bash
tensorflow>=2.0.0      # Redes neurais MLP
torch>=1.0.0           # STAB Transformer
scikit-learn>=1.0.0    # Algoritmos clÃ¡ssicos e mÃ©tricas
tabpfn>=0.1.0          # Modelo prÃ©-treinado tabular
```

### ğŸš€ **Algoritmos de Ensemble**
```bash
xgboost>=1.5.0         # Gradient boosting otimizado
lightgbm>=3.0.0        # Gradient boosting eficiente  
catboost>=1.0.0        # Especializado em categÃ³ricos
```

### ğŸ“Š **Data Science Stack**
```bash
pandas>=1.3.0          # ManipulaÃ§Ã£o de dados
numpy>=1.21.0          # ComputaÃ§Ã£o numÃ©rica
scipy>=1.7.0           # FunÃ§Ãµes cientÃ­ficas
matplotlib>=3.5.0      # VisualizaÃ§Ã£o bÃ¡sica
seaborn>=0.11.0        # VisualizaÃ§Ã£o estatÃ­stica
```

### **UtilitÃ¡rios**
```bash
joblib>=1.1.0          # PersistÃªncia de modelos
kagglehub>=0.1.0       # Download de datasets
optuna>=3.0.0          # OtimizaÃ§Ã£o de hiperparÃ¢metros
```

## Pipeline de Dados e Funcionalidades

### ğŸ§¹ **PrÃ©-processamento Inteligente**
```python
# FunÃ§Ãµes implementadas no notebook principal:
tratar_dados()                    # Limpeza e tratamento de inconsistÃªncias
create_engineered_features()      # Engenharia de features avanÃ§ada
preprocessing_for_trees()         # Pipeline especÃ­fico para modelos tree-based
preprocessing_for_neural_nets()   # Pipeline especÃ­fico para redes neurais
```

### ğŸ“ˆ **MÃ©tricas e AvaliaÃ§Ã£o Abrangente**
```python
# Sistema completo de mÃ©tricas implementado:
calcular_metricas()              # Accuracy, Precision, Recall, F1-Score
calcular_auc_roc()               # Ãrea sob a curva ROC
calcular_ks_statistic()          # EstatÃ­stica KS para discriminaÃ§Ã£o
plot_roc_curve()                 # VisualizaÃ§Ã£o da curva ROC
plot_ks_distribution()           # DistribuiÃ§Ãµes KS para anÃ¡lise
```

### ğŸ¯ **CaracterÃ­sticas Especiais do Projeto**

#### âœ¨ **Pontos Fortes Ãšnicos**
- **ğŸ“š DocumentaÃ§Ã£o 100% em PT-BR**: Todo cÃ³digo comentado em portuguÃªs brasileiro
- **ğŸ”„ Callbacks Personalizados**: Monitoramento ROC e KS durante treinamento
- **âš–ï¸ PrÃ©-processamento Diferenciado**: Pipelines especÃ­ficos por tipo de modelo
- **ğŸ¨ VisualizaÃ§Ãµes Ricas**: GrÃ¡ficos informativos e anÃ¡lises detalhadas
- **ğŸ”’ Reprodutibilidade**: Seeds fixas e ambiente controlado
- **ğŸ’¾ PersistÃªncia**: Modelos salvos automaticamente (.pkl, .h5, .pt)

#### ğŸ”¬ **Funcionalidades AvanÃ§adas**
- **Early Stopping**: PrevenÃ§Ã£o de overfitting com parada automÃ¡tica
- **Balanceamento de Classes**: Oversampling inteligente para dados desbalanceados
- **ValidaÃ§Ã£o Cruzada**: K-fold para robustez estatÃ­stica
- **OtimizaÃ§Ã£o de HiperparÃ¢metros**: GridSearch e busca manual
- **AnÃ¡lise de Feature Importance**: IdentificaÃ§Ã£o das variÃ¡veis mais relevantes

## ğŸ“‚ Dataset e MÃ©tricas de NegÃ³cio

### ğŸ“Š **Fonte dos Dados**
- **Dataset**: Customer Churn in Telecom Services
- **Origem**: Kaggle via kagglehub
- **Registros**: ~7,000 clientes
- **Features**: 20+ variÃ¡veis (demogrÃ¡ficas, serviÃ§os, financeiras)
- **Target**: Churn binÃ¡rio (Yes/No)

### ğŸ¯ **MÃ©tricas de NegÃ³cio para Churn**
| MÃ©trica | ImportÃ¢ncia | InterpretaÃ§Ã£o |
|---------|-------------|---------------|
| **Recall** | ğŸ”¥ CrÃ­tica | Capturar todos os clientes em risco |
| **Precision** | âš ï¸ Alta | Evitar falsos alarmes em campanhas |
| **KS Statistic** | ğŸ“ˆ Essencial | Capacidade de discriminaÃ§Ã£o (>0.3 = bom) |
| **AUC-ROC** | ğŸ“Š Importante | Performance geral (>0.8 = excelente) |
| **F1-Score** | âš–ï¸ Balanceamento | EquilÃ­brio entre precision e recall |

## ğŸ¯ Resultados e Performance

### **Estrutura de AvaliaÃ§Ã£o Robusta**
- **DivisÃ£o Estratificada**: Preserva distribuiÃ§Ã£o de classes
- **ValidaÃ§Ã£o Cruzada**: K-fold para estabilidade estatÃ­stica  
- **Holdout Test**: Conjunto de teste isolado para avaliaÃ§Ã£o final
- **AnÃ¡lise de Overfitting**: Early stopping e regularizaÃ§Ã£o

### ğŸ† **Modelos Salvos DisponÃ­veis**
Os seguintes modelos otimizados estÃ£o salvos e prontos para uso:
- `random_forest_best.pkl` - Melhor Random Forest com validaÃ§Ã£o cruzada
- `gradient_boosting_best.pkl` - Melhor Gradient Boosting com validaÃ§Ã£o cruzada  
- `xgboost_best.pkl` - Melhor XGBoost com validaÃ§Ã£o cruzada
- VersÃµes `*_without_kfold.pkl` - Modelos sem validaÃ§Ã£o cruzada para comparaÃ§Ã£o

## ğŸ“ Contexto AcadÃªmico e ContribuiÃ§Ãµes

### ğŸ“š **Objetivo Educacional**
Este projeto foi desenvolvido como trabalho acadÃªmico com foco em:
- âœ… **AplicaÃ§Ã£o prÃ¡tica** de tÃ©cnicas de machine learning e deep learning
- âœ… **ComparaÃ§Ã£o sistemÃ¡tica** entre diferentes algoritmos
- âœ… **DocumentaÃ§Ã£o educativa** em portuguÃªs brasileiro
- âœ… **Boas prÃ¡ticas** de desenvolvimento e organizaÃ§Ã£o de cÃ³digo
- âœ… **Metodologia cientÃ­fica** na avaliaÃ§Ã£o de modelos


*Projeto desenvolvido para fins acadÃªmicos - PrediÃ§Ã£o de Churn em TelecomunicaÃ§Ãµes - 2025*
